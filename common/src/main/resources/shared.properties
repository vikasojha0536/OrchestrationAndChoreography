#1=(default) all ordered items are available in stock microservice (complete success)
#-1=no ordered items are available in stock microservice (complete failure)
order.status.stock=1

#1=(default) all ordered payments are approved in payment microservice (complete success)
#-1=no ordered payments are approved in payment microservice (complete failure)
order.status.payment=1

#for the sake of this example, new orders and items from stock microservice will generate item number based
# on the below prefix (in a real case scenario this naive strategy shouldn't be used)
item.number.prefix=itemnumber

#max items allowed when generating orders (total of items rather than items per order)
max.items.allowed=1000

spring.kafka.consumer.bootstrap-servers: pkc-lzvrd.us-west4.gcp.confluent.cloud:9092
spring.kafka.bootstrap-servers: pkc-lzvrd.us-west4.gcp.confluent.cloud:9092
spring.kafka.admin.properties.bootstrap.servers: pkc-lzvrd.us-west4.gcp.confluent.cloud:9092
spring.kafka.admin.properties.security.protocol=SASL_SSL
spring.kafka.admin.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='MTZWFWNEJTBZNN6A' password='kGXStUctydkkx3IDOXe1zgrsMALvLX8bHys1fHJlRWdmbZLi/6erXuhxRfwzXYZD';
spring.kafka.admin.properties.sasl.mechanism=PLAIN
spring.kafka.admin.properties.client.dns.lookup=use_all_dns_ips
spring.kafka.consumer.auto-offset-reset: earliest
spring.kafka.consumer.key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
spring.kafka.properties.security.protocol=SASL_SSL
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='MTZWFWNEJTBZNN6A' password='kGXStUctydkkx3IDOXe1zgrsMALvLX8bHys1fHJlRWdmbZLi/6erXuhxRfwzXYZD';
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.properties.client.dns.lookup=use_all_dns_ips

spring.kafka.producer.bootstrap-servers: pkc-lzvrd.us-west4.gcp.confluent.cloud:9092
#spring.kafka.producer.key-serializer: org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
topic.name.order=t_order
topic.name.payment=t_payment
topic.name.stock=t_stock
topic.name.notification=t_notification

#time the Stream innerjoin window will be open in milliseconds
#to receive the answer of order processing from other services
kafka.join.window.duration.ms=120000

###Producer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.properties.enable.idempotence=true
spring.kafka.producer.properties.acks=-1
spring.kafka.producer.properties.retries=11111

###Stream
spring.kafka.streams.properties.security.protocol=SASL_SSL
spring.kafka.streams.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='MTZWFWNEJTBZNN6A' password='kGXStUctydkkx3IDOXe1zgrsMALvLX8bHys1fHJlRWdmbZLi/6erXuhxRfwzXYZD';
spring.kafka.streams.properties.sasl.mechanism=PLAIN
spring.kafka.streams.properties.client.dns.lookup=use_all_dns_ips
spring.kafka.streams.bootstrap-servers=pkc-lzvrd.us-west4.gcp.confluent.cloud:9092
spring.kafka.streams.properties.default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.default.value.serde=org.springframework.kafka.support.serializer.JsonSerde
spring.kafka.streams.properties.spring.json.trusted.packages="*"
spring.kafka.streams.state-dir=/tmp/streams/1
spring.kafka.streams.properties.processing.guarantee=at_least_once
spring.kafka.streams.cleanup.on-shutdown=true

###Consumer
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
#spring.kafka.consumer.properties.spring.json.trusted.packages=*
#spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true

#As topics are created with 3 partitions in the order service,
# this will avoid another service to create and auto assign a 1 partition only to itself
spring.kafka.consumer.properties.allow.auto.create.topics=false

###logging
logging.level.orchestrationandchoreography=DEBUG

###Schema registry AVRO example
#spring.kafka.properties.schema.registry.url=http://0.0.0.0:8085
#auto.create.topics.enable=true
#spring.kafka.properties.specific.avro.reader=true
